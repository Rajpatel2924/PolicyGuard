import requests

# --------------------------------------------------
# Ollama Configuration
# --------------------------------------------------
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "llama3"   # must exist in `ollama list`


def rewrite_policy(policy_text, gaps):
    """
    Rewrite and improve a cybersecurity policy using a local LLM (Ollama).
    Fully offline. Streamlit-safe.
    """

    # Defensive handling
    if not policy_text.strip():
        return "❌ Empty policy text provided."

    if gaps:
        gap_text = "\n".join(f"- {g}" for g in gaps)
    else:
        gap_text = "No major gaps identified."

    prompt = f"""
You are a cybersecurity policy expert.

Your task:
1. Review the given organizational policy.
2. Address the missing sections listed below.
3. Rewrite the policy to align with the NIST Cybersecurity Framework.
4. Improve clarity, structure, and compliance language.
5. Provide a short improvement roadmap at the end.

Missing Sections:
{gap_text}

Original Policy:
{policy_text}

Output Format:
=== Improved Policy ===
<well-structured improved policy>

=== Improvement Roadmap ===
- Bullet-pointed next steps
"""

    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False
    }

    try:
        response = requests.post(
            OLLAMA_URL,
            json=payload,
            timeout=300
        )

        # Do NOT crash Streamlit
        if response.status_code != 200:
            return f"❌ Ollama error {response.status_code}: {response.text}"

        data = response.json()

        # Safe extraction
        return data.get("response", "❌ No response generated by LLM.")

    except requests.exceptions.RequestException as e:
        return f"❌ Failed to connect to Ollama. Is it running?\n\n{str(e)}"
